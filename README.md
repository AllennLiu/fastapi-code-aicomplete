# FastAPI Code AI Complete

ä½¿ç”¨ `FastAPI` æ­é…é è¨“ç·´ `CodeGeeX2` æ¨¡å‹ï¼Œé€šé AI æ™ºèƒ½ç”Ÿæˆä»£ç¢¼

> ç›®å‰æ¸¬è©¦èµ·ä¾†ï¼Œä½¿ç”¨è‹±æ–‡è‡ªç„¶èªè¨€ä¾†æè¿°ä»£ç¢¼è¡¨ç¾æ¯”è¼ƒè‰¯å¥½ï¼Œç”¨ä¸­æ–‡æœƒçµ¦ä½ å¯«ä¸€äº›æ¯”è¼ƒå¥‡æ€ªç”šè‡³ä¸ç›¸é—œçš„åŠŸèƒ½å‡ºä¾†ã€‚
> ç¸½çš„ä¾†èªªï¼Œ**åŠŸèƒ½é‚„æ˜¯å¾ˆå¼·å¤§**ï¼Œç›®å‰æ­£åœ¨æ•´åˆ `CodeGeeX2-6B` + `ChatGLM3-6B` é‡åŒ–æ¨¡å‹ï¼Œä½¿å…©å€‹å‰å¤§çš„ä½œå“å¾ˆå¥½çš„è¢«ç©è½‰ï¼

å»ºç½® **Docker** é¡åƒä¾†æ‰“åŒ…æ•´å€‹ **API** æœå‹™æˆä¸€å€‹ç¨‹åº *(åŒ…å«æ¨¡å‹æ–‡ä»¶å¤§å° > `40G` )*

---

## ğŸ¥ æ•ˆæœæ¼”ç¤º

- `AI` ä¾æŒ‡å®šéœ€æ±‚ç”Ÿæˆä»£ç¢¼ ğŸ”— http://127.0.0.1:7860/ai/copilot/coding

  ![ai-coding](https://github.com/AllennLiu/fastapi-code-aicomplete/assets/27174570/2978ffa4-e08b-41d7-882e-f83c7011453e)

---

## ğŸŒ ç’°å¢ƒæº–å‚™

- æœ¬é …ç›®å·²ç¶“å°‡å·²é…ç½®å¥½çš„ç’°å¢ƒé¡åƒï¼Œæ¨åœ¨ `Dockerhub` ä¸Šäº†ï¼Œ**å¤§å° `27G`** *(å…§å«å·²è¼‰å…¥çš„é‡åŒ– `CodeGeeX2-6B` + `ChatGLM3-6B` æ¨¡å‹)*
- é¡åƒé€£çµï¼š[seven6306/pretrained-model:ai-fastapi-copilot](https://hub.docker.com/repository/docker/seven6306/pretrained-model/tags)
- å¦‚æœæ‚¨è¦æ‰‹å‹• Build **Docker** é¡åƒ `ai-fastapi-copilot` *(ä½¿ç”¨ Docker ä¾†é¿å…ç’°å¢ƒä¾è³´ç­‰å•é¡Œ)*

  ```bash
  docker build --no-cache -t seven6306/pretrained-model:ai-fastapi-copilot . \
    --build-arg "HTTP_PROXY=http://admin:ZD7EdEpF9qCYpDpu@10.99.104.250:8081/" \
    --build-arg "HTTPS_PROXY=http://admin:ZD7EdEpF9qCYpDpu@10.99.104.250:8081/" \
    --build-arg "NO_PROXY=localhost,127.0.0.1,.example.com"
  # æ›ä»£ç† --build-arg æ˜¯æˆ‘å…§éƒ¨ç’°å¢ƒç”¨çš„ï¼Œå¯ä»¥åˆªé™¤
  ```

---

## ğŸš€ å¿«é€Ÿé–‹å§‹

- å•Ÿå‹• **API** æœå‹™ï¼Œé€™è£¡å•Ÿç”¨äº† **GPU Driver** è«‹ç¢ºä¿å®‰è£ Docker çš„ç³»çµ±ç’°å¢ƒå·²å®‰è£ `cuda-toolkit`ï¼Œå¦‚æœç”¨ CPU è«‹åˆªé™¤ `--gpus all` èˆ‡ `-e "LOAD_MODEL_DEVICE=gpu"` å…©å€‹åƒæ•¸ã€‚

  ```bash
  docker run -tid -p 7861:22 -p 7860:7860 \
    --gpus all \
    -e "LOAD_MODEL_DEVICE=gpu" \
    -v /etc/timezone:/etc/timezone:ro \
    -v /etc/localtime:/etc/localtime:ro \
    -v /root/.ssh:/root/.ssh:ro \
    --ulimit nofile=65535 --privileged=true --restart=always \
    --name copilot seven6306/pretrained-model:ai-fastapi-copilot
  ```

- ç”Ÿæˆç¬¬ä¸€å€‹ `Python` è…³æœ¬ *(æ²’æœ‰ `jq` å·¥å…·çš„è©±ï¼Œéœ€è‡ªè¡Œå°‡ response æ–‡æœ¬è²¼åœ¨è…³æœ¬ä¸­)*
  <br>å¦‚æœåœ¨ **Request Body** å¤šæ·»åŠ åƒæ•¸ **`, "html": true`**ï¼Œå¯ä»¥ç›´æ¥è¿”å› `HTML` ä»£ç¢¼æ–‡æœ¬

  ```bash
  curl -sX POST http://172.17.1.243:7860/ai/copilot \
    -H 'Content-Type: application/json'\
    -d '{ "lang": "Python", "prompt": "å¯«ä¸€å€‹ç¨‹åºåŸ·è¡Œå‘½ä»¤ ipmitool raw 6 1 åˆ¤æ–· 00 åœ¨è¿”å›å€¼ä¸­æ‰“å° Pass ä¸åœ¨å°±æ‰“å° Fail" }' | jq -r .response | tee test.py
  ```

  ```bash
  {
      "response": "\n\nimport os\nimport sys\n\n\ndef run_cmd(cmd):\n    p = os.popen(cmd)\n    return p.read()\n\n\ndef get_status(cmd):\n    p = os.popen(cmd)\n    return p.read()\n\n\ndef get_status_code(cmd):\n    p = os.popen(cmd)\n    return p.read()\n\n\nif __name__ == \"__main__\":\n    cmd = \"ipmitool raw 6 1\"\n    cmd_status = \"ipmitool raw 6 1 | grep '00'\"\n    cmd_status_code = \"ipmitool raw 6 1 | grep '00' | wc -l\"\n\n    print(run_cmd(cmd))\n    print(get_status(cmd_status))\n    print(get_status_code(cmd_status_code))\n\n    if \"00\" in get_status(cmd_status):\n        print(\"Pass\")\n    else:\n        print(\"Fail\")\n\n\n\"\"\"\nipmitool raw 6 1 | grep '00'\nipmitool raw 6 1 | grep '00' | w\n\"\"\"",
      "lang": "Python",
      "elapsed_time": 22.534089,
      "datetime": "2024-06-07 05:45:26"
  }
  ```

- å¯ä»¥æ­£å¸¸åŸ·è¡Œ AI ç”Ÿæˆçš„ `Python` è…³æœ¬ä¸¦ç¬¦åˆé æœŸï¼

  ```bash
  root@debian:~# python test.py
  20 00 02 12 02 8d dd b3 00 18 00 00 00 00 00

  20 00 02 12 02 8d dd b3 00 18 00 00 00 00 00

  1

  Pass
  ```

  ![api_demo](https://github.com/AllennLiu/fastapi-code-aicomplete/assets/27174570/752d6d17-47a8-4c89-b31b-b03c962703fe)

---

## ğŸ˜µ Troubleshooting

- å¦‚ä½•ç›£æ§ GPU åˆ©ç”¨ç‡ï¼Ÿæœ¬åœ°è«‹å…ˆå®‰è£ `cuda-toolkit` å·¥å…·ï¼Œå®¹å™¨å‰‡æœƒè‡ªè¡Œåµæ¸¬ã€‚

  ```bash
  watch nvidia-smi
  ```

  ```bash
  Every 2.0s: nvidia-smi                                                                                                                                                                                                                                   Blade-Allen: Fri Jun  7 21:06:49 2024

  Fri Jun  7 21:06:49 2024
  +-----------------------------------------------------------------------------------------+
  | NVIDIA-SMI 550.69                 Driver Version: 551.95         CUDA Version: 12.4     |
  |-----------------------------------------+------------------------+----------------------+
  | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
  | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
  |                                         |                        |               MIG M. |
  |=========================================+========================+======================|
  |   0  NVIDIA GeForce RTX 4070 ...    On  |   00000000:01:00.0 Off |                  N/A |
  | N/A   47C    P0             20W /  105W |       0MiB /   8188MiB |      0%      Default |
  |                                         |                        |                  N/A |
  +-----------------------------------------+------------------------+----------------------+

  +-----------------------------------------------------------------------------------------+
  | Processes:                                                                              |
  |  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
  |        ID   ID                                                               Usage      |
  |=========================================================================================|
  |  No running processes found                                                             |
  +-----------------------------------------------------------------------------------------+
  ```

---

## ğŸ—‚ åƒè€ƒä¾†æº

- https://github.com/THUDM/CodeGeeX2
- https://github.com/li-plus/chatglm.cpp
- https://github.com/THUDM/ChatGLM3/tree/main
